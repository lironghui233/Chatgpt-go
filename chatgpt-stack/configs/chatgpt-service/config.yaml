server:
  host: "0.0.0.0"
  port: 50051
  access_token: "05nr9jey84prEhw5u43780yjr3h7sksSdkFdDngKie8nth0yi294"
chat:
  # chatgpt apikey
  api_key: "ksSdkFdDngKie8nth0yi29405nr9jey84prEhw5u43780yjr3h7s"
  # chatgpt 接口地址
  base_url: "http://172.26.0.6:4002/v1"
  # 使用的训练模型
  model: "gpt-3.5-turbo-0301"
  # 单次请求的上下文总长度，包括 请求消息+completion.maxToken 两者总计不能超过4097
  max_tokens: 4096 
  # 表示语言模型输出的随机性和创造性
  # 取值范围 0 ~ 1，值越大随机性和创造性越高
  temperature: 1 
  # 用于生成文本时控制选词的随机程度
  # 即下一个预测单词考虑的概率范围
  # 取值范围 0 ~ 1，例如：0.5 表示考虑选择的单词累计概率大于等于0.5
  top_p: 0.9
  # 存在惩罚，用于生成文本时控制重复使用单词的程度
  # 取值 0 ~ 1,0表示不惩罚，1表示完全禁止重复单词
  # 完全禁止重复单词会影响生成文本的流畅性和连贯性
  presence_penalty: 0.8
  # 用于控制模型生成回复时重复单词出现的频率
  # 取值 0 ~ 1，值越大生成的回复会更注重避免使用已经出现的单词
  frequency_penalty: 0.5
  # AI助手特征描述
  bot_desc: ""
  # 上下文缓存时长，单位s
  context_ttl: 1800
  # 上下文消息条数
  context_len: 4 
  # 单次请求，保留的响应tokens数量
  min_response_tokens: 2048
redis:
  # 确保chatgpt-service能访问redis所在的ip，这里最好是配置公网ip，满足分布式部署
  host: "172.26.0.6"
  port: 6379
  pwd: "123456"
dependOnServices:
  tokenizer:
    address: "http://tokenizer:3003"
  chatgpt-data:
    address: "chatgpt-data:50052"
    access_token: "9jey84prEhw5u43780yjr3h7sksSdkFdDngKie8nth0yi29405nr"
  sensitive-words:
    address: "sensitive-words:50053"
    access_token: "9jey84prEhw5u43780yjr3h7sksSdkFdDngKie8nth0yi29405nr"
  keywords:
    address: "keywords:50054"
    access_token: "9jey84prEhw5u43780yjr3h7sksSdkFdDngKie8nth0yi29405nr"
log:
  # panic,fatal,error,warn,warning,info,debug,trace
  level: "info"
  log_path: "runtime/app.log"
